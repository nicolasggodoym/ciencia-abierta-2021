---
title: "Importar, explorar y limpiar datos"
linktitle: "3: Importar, explorar y limpiar datos"
date: "2021-08-23"
menu:
  example:
    parent: Ejemplos
    weight: 3
type: docs
toc: true
editor_options: 
  chunk_output_type: console
---

## 0. Objetivo del práctico

Este práctico tiene por objeto introducir a las y los estudiantes del curso en herramientas que les permitan a) **importar bases de datos en diversos formatos**; b)**seleccionar variables** de las bases de datos importadas; c) limpiar los datos, eliminando las filas con casos perdidos; y d) **exportar bases de datos** procesadas. Para ello, se trabajará con los paquetes `haven` (que forma parte, a su vez, del mundo de paquetes `tidyverse`), y `dplyr`, para poder importar  y exportar los datos, y manipular estos datos, respectivamente.

## 1. Recursos de la práctica

Para el correcto trabajo de estos materiales, deben descargar los datos de la *Encuesta de Caracterización Socioeconómica (CASEN)* en su versión 2020. Para ello, deben dirigirse al [siguiente enlace](https://drive.google.com/drive/folders/1Orgb3Qb9LcjTfjYMdIdy7SWd3xDMrTbG?usp=sharing), descargar el archivo **datoscasen.sav**, y pegarlo en la carpeta _input/data_ de su repositorio. 

Recuerden siempre consultar el [**manual/libro de códigos**](http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Libro_de_codigos_Base_de_Datos_Casen_en_Pandemia_2020.pdf) antes de trabajar una base de datos.

## 2. Librerias a utilizar

En este práctico utilizaremos cuatro paquetes

1. `pacman`: este facilita y agiliza la lectura de los paquetes a utilizar en R

2. `sjmisc`: explorar datos

3. `tidyverse`: colección de paquetes, del cuál utilizaremos `dplyr` y `haven`

4. `haven`: cargar y exportar bases de datos en formatos .sav y .dta

5. `readxl` y `writexl`: para cargar y exportar bases de datos en formato .xlsx y .xls

6. `dplyr`: nos permite seleccionar variables de un set de datos

# Pasos del procesamiento

## 1. Cargar librerías

Dado que ya cargamos `pacman` en el práctico anterior, no lo debemos volver a instalar. Ahora bien, si  cargaremos los nuevos paquetes. Les recordamos que cuando luego de un paquete ponemos `::` esto se refiere a que se *"fuerza"* que esa función provenga de *ese paquete*

```{r packages, include=TRUE}
pacman::p_load(sjmisc,
               sjPlot,
               tidyverse,
               haven,
               readxl,
               writexl)
```

## 2. Importar datos

Para poder realizar análisis estadístico de cualquier tipo, el primer paso - sin considerar, por supuesto, la formulación de un problema de investigación, y la búsqueda de datos que permitan resolverlo - es **importar una base de datos**. Por razones obvias, si no hemos cargados los datos en el *entorno*, no seremos capaces de realizar ningún otro procedimiento, ni de preparación de los datos - por ejemplo, seleccionar variables, recodificarlas, construir variables sumativas, entre otros -, ni de análisis de estos - ya sean descriptivos, relacionales, explicativos, y así. 

Una de las bondades de **R** es que es posible importar fácilmente datos que se encuentren en *cualquier formato*: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .RData. Para poder hacerlo, sin embargo, lo primero es *instalar* y *cargar* las **librerías** que contienen las **funciones** necesarias para la importación de distintos tipos de archivos. 


### 2.1. Cargar set de datos

Una vez cargado el paquete `haven`, procedemos a *importar* los datos anteriormente mencionados. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con `read_sav()`, crearemos un objeto llamado `datos`. Si este procedimiento se logra, esto aparecerá en el *Enviroment*.

```{r load, include=FALSE, warning= FALSE , message = F}
temp <- tempfile()
download.file("http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Casen_en_Pandemia_2020_SPSS.sav.zip",temp)
datos <- haven::read_sav(unz(temp, "Casen en Pandemia 2020 SPSS.sav"))
unlink(temp); remove(temp)
```

Antes ¿dónde están nuestros datos? Por lo general, nuestros datos los dejaremos en la carpeta `input/data`. En el [siguiente enlace](https://drive.google.com/drive/folders/1Orgb3Qb9LcjTfjYMdIdy7SWd3xDMrTbG?usp=sharing) podrán descargar el archivo .zip que contiene la base de CASEN. Si aún no sabes como descomprimir datos, por favor revisa [aquí](https://learn-r-udp.netlify.app/resource/unzipping/). 

Luego de que hayas **descargado y descomprimido los datos** asegurate de dejar el archivo `.sav` y `.dta` en la carpeta de tu proyecto `input/data`. Los datos se llamarán en formato SPPS `Casen en Pandemia 2020 SPSS.sav` o en STATA `Casen en Pandemia 2020 SPSS.dta`.


{{< div "note" >}}
Para **importar** los datos en R debemos tener en consideración tres cosas:

1. Cómo se llaman los datos (en nuestro caso Casen en Pandemia 2020 SPSS)

2. El formato de nuestros datos (en nuestro caso .sav)

3. El lugar de donde están alojados nuestros datos. 
{{< /div >}}

El [paquete `haven`](https://haven.tidyverse.org/) tiene una serie de funciones para cargar datos llamadas `read_*` (el asterisco indica el formato). Para oculparlo solo debes tener en claro los puntos anteriores

`read_*("ruta_hacia_archivo/nombre_archivo.*"``. En nuestro caso:


```{r read, echo = T, eval = F}
datos <- read_sav("Casen en Pandemia 2020 SPSS.sav")  # No funciona
datos <- read_sav("input/data/casen en pandemia 2020 SPSS.sav") # No funciona
datos <- read_sav("input/data/Casen en Pandemia 2020 SPSS.sav") 
```

Los dos primeros comandos no funcionan porque

1. La ruta no está bien definida

2. El nombre de la base no es exacto

¡Dos errores muy frecuentes cuando uno se inicia! Ahora, ¿cómo se si está bien mi base? Primero, notarás que en tu **Enviroment** se ha creado un objeto. En nuestro caso objeto posee`r format(ncol(datos), decimal.mark="," , big.mark = ".")` variables (columnas), pero conserva las filas `r format( nrow(datos), decimal.mark="," , big.mark = ".")` (u observaciones)

¡Ahora es tu turno! Intenta hacer este procedimiento con los datos en `.dta`. También puedes encontrar este archivo en el enlace.

### 2.1.1 Cargar set de datos en otros formatos. 

Ahora bien, no siempre este procedimiento será tan fácil sobre todo pues no siempre vendrán en formatos "limpios". La gran forma de lidiar con eso es con la **manipulación de datos** (algo que nos tomará tiempo en este curso), pero de todas formas es de gran ayuda utilizar de manera correcta la importación de datos. Nos puede solucionar varios problemas de codificación y lectura. 

Para poder abordar esto de la mejor manera es necesario utilizar funciones *ad hoc* al formato de nuestros datos. Como se mencionó anteriormente, con R es muy flexible en esto. En los siguientes pasos les mostraremos como cargar en otros formatos y reconociendo algunos de los *problemas comunes con los cuáles te encontrarás* (de seguro...)

#### a) `.dta`

Este es el formato específico de base de datos para STATA. Por ello, utilizaremos la función `read_dta()` (también está como `read_stata()`), incluida en el paquete `haven`.

```{r, setup, echo = T, include=FALSE}
datos <- read_dta("input/data/Casen en Pandemia 2020 SPSS.dta") 
```

#### b) .RData y .rds

¿Y R tiene formato de datos? ¡Sí! Como son propios del programa **no es necesario cargar paquetes** pues sus funciones provienen del paquete  `base`. La diferencia básica entre `.RData` y `.rds` es que `.rds` puede contener solo un objeto del *Enviroment* de R, mientras que `.RData` puede contener múltiples objetos que han sido guardados en `.rds`.

{{< div "note" >}}
*Leer un objeto proveniente de un archivo*

readRDS(file = "datos.rds")

*Leer múltiples objetos a un archivo*
load(file = "datos.RData")
{{</div>}}

Además de **nunca olvidar la ruta**, no debes olvidar una diferencia de codificación entre ambas funciones: con `load()` los objetos se cargan *automáticamente* en el ambiente, mientras que en `readRDS()` no. Solamente "llama" a los archivos, pero no los deja como un objeto dentro del *Enviroment*. 

```{r}
load(file = "input/data/CASEN.RData")
readRDS(file = "input/data/CASEN.rds")
```

```{r}
datos <- readRDS(file = "input/data/CASEN.rds")
```


¿Solo contiene datos? ¡No! Además de que puede contener múltiples datos, puede guardar otros *objetos* que se creen en su proceso estadístico. Por ejemplo, *modelos* ¡Lo veremos más adelante!

#### c) `.csv`

Los archivos en `.csv` o `.txt` son de frecuente uso dado que son más livianos que un archivo en `.dta` o `.sav` por el *meta-data* que contienen (información adicional, además de columnas-filas). El paquete `utils` de `R base` tiene una función de muy buena calidad llamada `read.table` (`read.csv()` para archivos en `.csv` y `read.delim()` para archivos en `.txt`)

Su estructura es muy simple `read.*(file = "datos.*")`. Ahora bien tiene una serie de argumentos que permiten leer de mejor manera los archivos **y de seguro los ocuparás**:

- [`sep`]: indica con qué están separadas las columnas (*; , -*)

- [`dec`]: indica como están separados los decimales (*. ,*)

- [`na-strings`]: indica como están codificados los `NA` (¡podría ser más de una forma!)

- [`encoding`]:puede ser `UTF-8` o `Latin-1`

- [`skip`]: indica el *número* de filas que hay que saltarse (no siempre los csv y excel parten en la primera fila). El argumento `nrow` indica el número de filas máximas a leer

- [`stringsAsFactors`]: si se indica verdadero (`TRUE`) los carácteres serán transformados en factores, lo cuál será muy útil en caso de necesitar hacer análisis.

```{r, eval = F}
datos <- read.csv("input/data/CASEN.csv", sep=",", 
                  encoding = "UTF-8", stringsAsFactors = F)

head(datos)
```

Muchos problemas, ¡vamos solucionado!

```{r, eval = F}
datos <- read.csv("input/data/CASEN.csv", sep=";", 
                  encoding = "Latin-1", stringsAsFactors = F, na.strings = c("No sabe", NA))

```


#### d) `.xlsx` 

A partir del paquete `readxl` de `tidyverse` podremos obtener datos que provienen de Excel (tanto en formato `.xls` como `.xlsx`). Ocuparemos la función `read_excel()`, la cual tiene similares argumentos a `read.csv()`

{{< div "note" >}}
`read_excel("datos.xlsx", sheet = "Hoja 1", range = "A1:C40")`
`read_excel("datos.xlsx", sheet = 2, skip = 4, na = "No sabe")`
{{</div>}}

```{r}
datos <- readxl::read_excel(path = "input/data/CASEN.xlsx")
```

¡Hemos sido engañados/as! ¿Cómo solucionar?

```{r}
datos <- readxl::read_excel(path = "input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1)

datos <- readxl::read_excel(path = "input/data/CASEN.xlsx", sheet = "Hoja1", skip = 1, na = "NA")

```

Para seguir con este ejercicio volvamos a utilizar la base original en `.dta`

```{r}
datos <- read_dta("input/data/Casen en Pandemia 2020 STATA.dta") 
```


## 3. Explorar datos 

Lo más probable es que, una vez importados los datos a utilizar, no trabajemos con el total de variables incluidas en estos (que, en este caso, suman un total de *650* columnas). Es por ello, que debemos **seleccionar** las variables de interés para resolver nuestro problema de investigación (sea el que sea). 

Antes de seleccionar las variables debemos **explorar nuestros datos**, si no ¿cómo saber qué seleccionar y qué no? En R base las funciones clásicas para explorar datos son

```{r eval = F}
View(datos) # Ver datos
names(datos) # Nombre de columnas
dim(datos) # Dimensiones
str(datos) # Estructura de los datos (las clases y categorias de repuesta)
```

A pesar de que son fáciles de aprender, no tienen una visualización muy amena. Un excelente paquete para explorar datos es `sjmisc` quien tiene tres funciones claves:

- [`View_df()`]: que en el visor "Viewer" les mostrará una tabla que tiene el nombre de variable, etiqueta y categorías de respuesta

- [`find_var()`]: que permite indagar en variables que estamos buscando según sus temáticas

- [`frq()`]: nos otorga la distribución univariada de variables categóricas que estamos explorando

- [`descr()`]: nos otorga estadísticos de tendencia central para la variable numérica seleccionada. 

*Ver datos en el visor*
```{r}
sjPlot::view_df(datos)
```

*Buscar variables sobre temáticas relacionadas a "vivienda" (no olvides dejarla entre comillas)*
```{r}
find_var(datos, "pobreza")
find_var(datos, "salario")
```

**Explorar distirbución de las variables**
```{r}
frq(datos$pobreza)
frq(datos$y1) #¡Qué feo!
```

Para las variables numeric, en cambio, podemos utilizar la función `descr()` del mismo paquete, que nos indicará las *medidas de tendencia central, dispersión y posición* de la variable.

```{r, setup, echo = T, include=FALSE}
descr(datos$y1)
```


#### Sobre las clases de las variables

Un punto que ya se hace evidente de empezar a trabajar son como reconocer y trabajar **los distintos tipos de variables en R**. Si bien al inicio no es tan intuitivo ¡no te preocupes! Cuando uno avanza en el aprendizaje del programa de a poco estos conceptos se asimilan más. 

Partamos por lo básico que ustedes ya saben de sus cursos de estadística: **los niveles de medición**:  sabemos que el nivel de medición de la variable *género* es *nominal* y, por lo tanto, sólo nos permite clasificar a unas personas u otras. Por ello, no podemos, por ejemplo, calcular el promedio del género de una muestra. Por otra parte, la variable *edad* presenta un nivel de medición *de razón*, por lo cual sí podemos realizar con ella operaciones aritméticas y, en consecuencia, es posible, por ejemplo, calcular el promedio de edad de la muestra con que estamos trabajando. 

La función `class()`, incluido en el *paquete base* de R, nos permite saber la *clase* de una variable determinada con la cual deseemos trabajar. También nos permite conocer la clase de otros objetos en R, pero no es algo que utilizaremos (aún).

### a) `numeric`

Una variable puede presentar la clase  `numeric`, lo cual significa que sus datos *sólo incorporan números*. Así, es posible, por ejemplo, calcular el promedio para este tipo de variables. En *Casen en Pandemia 2020*, una de las variables `numeric` incluidas es *Ingreso total per cápita del hogar corregido* (codificada como ypchtotcor).

```{r, setup, echo = T}
class(datos$ypchtotcor)
```

### b) `character`

Una variable de clase `character` puede incluir tanto números como letras. Si bien con estas variables no es posible calcular, por ejemplo, promedios, sí podemos calcular frecuencias (absolutas y relativas), entre otros. 

### c) `Logic`

Una variable de clase `Logic` incluye valores lógicos, como TRUE (T) o FALSE (F). Los valores nulos (NA) también son valores lógicos. Este tipo de variables nos pueden servir a la hora de crear funciones, lo cual no se revisará en este práctico.

### d) `factor`

Una variable de clase `factor` puede incluir tanto números como letras. Es una especie de variable `character`, pero recodificada de modo que los posibles valores sean etiquetados. Las bases de datos no suelen incluirlas a priori, por lo que lo usual es que debamos realizar un proceso de *recodificación* para poder trabajar una variable como factor. ¡Esto último será tratado en el siguiente práctico!

#### En resumen:

| Clase  | Tipo de variable |
|---------:|:--------|
| `numeric` | Cuantitativa |
| `character` | Categórica |
| `Logic` |  Lógica (TRUE, FALSE, NA) |
| `factor` | Categórica con niveles y etiquetas |


## 3.1. Selección de variables

Luego de revisar el nivel de medición de las variables y reconociendo la distribución de los datos que tenemos, es evidente que lo mejor es solamente trabajar con un *subset* de una base de datos con las variables que queremos transformar.

Para asegurarnos que variables queremos utilizar deberíamos ir al libro de códigos, pero también podemos elegir y decidir de manera más certera qué variables incorporar a partir de la revisión con `find_var()`. En esta sección no profundizaremos distintas formas de seleccionar datos. Solo les mostraremos de manera simple como seleccionar dos variables de nuestro interés:

- `ypchtotcor`: Ingresos del hogar
- `v13`: "Su hogar, ¿bajo qué situación ocupa la vivienda?"
- `v29`: "¿Cuántos dormitorios de uso exclusivo ocupa su hogar en esta vivienda?"
- `p6`: "¿Cuántas personas viven habitualmente en esta vivienda?"

Crearemos una base procesada llamado `datos_proc`, que sólo incluirá estas tres variables. 

```{r, setup, echo = T, include=FALSE}
datos_proc <- select(datos, ypchtotcor,v13,v29,p6)
```

Como podemos ver en el ambiente (Environment), se creó un nuevo objeto llamado `datos_proc`, que tiene la misma cantidad de observaciones (filas) que datos, pero que sólo incluye 4 de las 650 variables iniciales. 

## 4. Limpieza de datos

Los datos con los que trabajamos suelen incorporar valores nulos (`NA`), casos perdidos ingresados como valores de clase `Logic`. Estos valores no nos entregan información útil para nuestros análisis, y pueden generar problemas al momento de, por ejemplo, calcular _medidas de tendencia central_, u otros procedimientos estadísticos.

Hay diversas maneras de trabajar los valores nulos, tales como realizar procesos de imputación, entre otros. Sin embargo, la más sencilla consiste en **eliminar los valores nulos** que se encuentran presentes en nuestros datos (aunque no recomendable)

Para ello, lo primero es _identificar valores nulos_ en el set de datos en general, o en alguna variable en específico. Para ello, empleamos la función `is.na()`.

```{r}

is.na(datos_proc) #Revisamos si hay casos perdidos en el total del set de datos 
is.na(datos_proc$ypchtotcor) #Revisamos si hay casos perdidos en Ingresos per cápita

```

Sin embargo, esto no resulta muy práctico para el análisis. Es por ello que emplearemos la función `sum()` para _contar cuántos valores nulos_ hay en el set de datos en general, o en alguna variable en particular. 

```{r}

sum(is.na(datos_proc)) #Contamos los valores nulos del set de datos en general, que suman un total de 180.148
sum(is.na(datos_proc$ypchtotcor)) #Contaremos los valores nulos de la variable Ingresos per cápita, que alcanzan un total de 98

```

Una vez identificamos los _valores nulos_, podemos proceder a **eliminarlos** del set de datos. El comando `na.omit()` eliminará _todas las filas_ que presenten casos perdidos. 

```{r}
nrow(datos_proc)
datos_proc <- na.omit(datos_proc) #Eliminamos las filas con casos perdidos
nrow(datos_proc) #La nueva base de datos tiene 5.387 filas y 4 columnas
```

¡La próxima sesión aprenderemos a recodificarlas!

## 5. Guardar y exportar datos

Por último, una vez que hayamos procesado los datos, es importante que los **guardemos** en una nueva base de datos procesada, para no tener que llevar a cabo el procesamiento otra vez.

Al igual que en el paso de carga de datos, y a partir del flujo de `input-R-output`propuesto, es esperable que estos datos procesados (o intermedios) los guardemos en `output/data` para que se entienda que provienen de un proceso de manipulación personal

El archivo se puede guardar en distintos formatos: 

### a) .RData y .rds


{{< div "note" >}}
*Guardar un objeto a un archivo*

saveRDS(objecto, file = "datos.rds")

*Guardar un objeto a un archivo*
save(objeto1, objeto2, file = "datos.RData)
{{</div>}}

Es lo recomendable, si el resto del análisis lo realizaremos en R. 

```{r, setup, echo = T, include=FALSE}
save(datos_proc, file = "output/data/datos_proc.RData") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.RData. 

saveRDS(datos_proc, file= "output/data/datos_proc.rds") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.rds. 
```

### b) .sav (`haven`)

```{r, setup, echo = T, include=FALSE}
write_sav(datos_proc, "output/data/datos_proc.sav") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.sav. 
```

### b) .dta (`haven`)

```{r, setup, echo = T, include=FALSE}
write_dta(datos_proc, "output/data/datos_proc.dta") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.dta. 
```

### b) .csv

```{r, setup, echo = T, include=FALSE}
write.csv(datos_proc, "output/data/datos_proc.csv") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.csv. 
```

### b) .xlsx

```{r, setup, echo = T, include=FALSE}
writexl::write_xlsx(datos_proc, "output/data/datos_proc.xlsx") #Guardamos el objeto datos_proc en la ruta de trabajo actual, bajo el nombre de datos_proc.xlsx. 
```

## Resumen

¡Eso es todo por este práctico! Aquí, aprendimos a: 
- 1) Importar datos en diferentes formatos.
- 2) Seleccionar variables (y hacer una revisión de ciertos aspectos de estas).
- 3) Limpiar los datos, eliminando casos perdidos
- 4) Guardar y exportar los datos procesados, en distintos formatos.

## Reporte de progreso

¡Recuerda rellenar tu [reporte de progreso](https://learn-r.formr.org/). Te llegó un código único a tu correo electrónico. Mediante él debes acceder para actualizar tu estado de avance del curso.